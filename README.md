# chat_rag_voice_local_ai
chat_rag_voice_local_ai â€” A single self-contained application running in VS Code: offline, voice-enabled RAG assistant that listens, thinks, and speaks using local embeddings and on-device LLMs. Private. Secure. Fast. Always available without the cloud.

--

## ğŸ§  Features
- ğŸ’¬ Voice-driven natural conversation  
- ğŸ§± Local RAG memory using SQLite + `sqlite-vec`  
- ğŸ—£ï¸ Text-to-speech (TTS) responses  
- ğŸ”’ Fully offline â€” no external API calls  
- âš¡ Fast startup and low resource use  
- ğŸ§© Designed for MS AI Toolkit / VS Code runtime  

---

## âš™ï¸ Setup Instructions (VS Code + Python 3.11.9)

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/wpbest/chat_rag_voice_local_ai.git
cd chat_rag_voice_local_ai

2ï¸âƒ£ Create and activate a virtual envir

2ï¸âƒ£ Create and activate a virtual environment with Python 3.11.9

Windows (PowerShell):

py -3.11 -m venv .venv
.venv\Scripts\activate


macOS / Linux:

python3.11 -m venv .venv
source .venv/bin/activate

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Open in VS Code

Open the project folder in VS Code

Press Ctrl + Shift + P â†’ Python: Select Interpreter â†’ choose the one from .venv

Check if the LLM is running
Invoke-RestMethod http://127.0.0.1:5272/v1/models   

Then open the terminal and run:

python chat_rag_voice_local_ai.py

5ï¸âƒ£ Speak and interact

After the warm-up, AVA will say:

â€œGet Ready to Say something when I say I am Listeningâ€¦â€

Now you can talk to your offline assistant.